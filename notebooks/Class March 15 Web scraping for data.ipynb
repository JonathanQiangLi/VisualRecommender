{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\n",
      "  Downloading Scrapy-1.5.0-py2.py3-none-any.whl (251kB)\n",
      "\u001b[K    100% |████████████████████████████████| 256kB 430kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting PyDispatcher>=2.0.5 (from scrapy)\n",
      "  Downloading PyDispatcher-2.0.5.tar.gz\n",
      "Collecting Twisted>=13.1.0 (from scrapy)\n",
      "  Downloading Twisted-17.9.0.tar.bz2 (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.0MB 369kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cssselect>=0.9 (from scrapy)\n",
      "  Downloading cssselect-1.0.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: lxml in /Users/jonathan/anaconda2/lib/python2.7/site-packages (from scrapy)\n",
      "Collecting service-identity (from scrapy)\n",
      "  Downloading service_identity-17.0.0-py2.py3-none-any.whl\n",
      "Collecting w3lib>=1.17.0 (from scrapy)\n",
      "  Downloading w3lib-1.19.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyOpenSSL in /Users/jonathan/anaconda2/lib/python2.7/site-packages (from scrapy)\n",
      "Collecting parsel>=1.1 (from scrapy)\n",
      "  Downloading parsel-1.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/jonathan/anaconda2/lib/python2.7/site-packages (from scrapy)\n",
      "Collecting queuelib (from scrapy)\n",
      "  Downloading queuelib-1.4.2-py2.py3-none-any.whl\n",
      "Collecting zope.interface>=3.6.0 (from Twisted>=13.1.0->scrapy)\n",
      "  Downloading zope.interface-4.4.3.tar.gz (147kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 785kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting constantly>=15.1 (from Twisted>=13.1.0->scrapy)\n",
      "  Downloading constantly-15.1.0-py2.py3-none-any.whl\n",
      "Collecting incremental>=16.10.1 (from Twisted>=13.1.0->scrapy)\n",
      "  Downloading incremental-17.5.0-py2.py3-none-any.whl\n",
      "Collecting Automat>=0.3.0 (from Twisted>=13.1.0->scrapy)\n",
      "  Downloading Automat-0.6.0-py2.py3-none-any.whl\n",
      "Collecting hyperlink>=17.1.1 (from Twisted>=13.1.0->scrapy)\n",
      "  Downloading hyperlink-17.3.1-py2.py3-none-any.whl (73kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 1.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting attrs (from service-identity->scrapy)\n",
      "  Downloading attrs-17.4.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules (from service-identity->scrapy)\n",
      "  Downloading pyasn1_modules-0.2.1-py2.py3-none-any.whl (60kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.2MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting pyasn1 (from service-identity->scrapy)\n",
      "  Downloading pyasn1-0.4.2-py2.py3-none-any.whl (71kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 1.8MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: cryptography>=1.9 in /Users/jonathan/anaconda2/lib/python2.7/site-packages (from pyOpenSSL->scrapy)\n",
      "Requirement already satisfied: setuptools in /Users/jonathan/anaconda2/lib/python2.7/site-packages (from zope.interface>=3.6.0->Twisted>=13.1.0->scrapy)\n",
      "Requirement already satisfied: idna>=2.1 in /Users/jonathan/anaconda2/lib/python2.7/site-packages (from cryptography>=1.9->pyOpenSSL->scrapy)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /Users/jonathan/anaconda2/lib/python2.7/site-packages (from cryptography>=1.9->pyOpenSSL->scrapy)\n",
      "Requirement already satisfied: enum34 in /Users/jonathan/anaconda2/lib/python2.7/site-packages (from cryptography>=1.9->pyOpenSSL->scrapy)\n",
      "Requirement already satisfied: ipaddress in /Users/jonathan/anaconda2/lib/python2.7/site-packages (from cryptography>=1.9->pyOpenSSL->scrapy)\n",
      "Requirement already satisfied: cffi>=1.7 in /Users/jonathan/anaconda2/lib/python2.7/site-packages (from cryptography>=1.9->pyOpenSSL->scrapy)\n",
      "Requirement already satisfied: pycparser in /Users/jonathan/anaconda2/lib/python2.7/site-packages (from cffi>=1.7->cryptography>=1.9->pyOpenSSL->scrapy)\n",
      "Building wheels for collected packages: PyDispatcher, Twisted, zope.interface\n",
      "  Running setup.py bdist_wheel for PyDispatcher ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/jonathan/Library/Caches/pip/wheels/86/02/a1/5857c77600a28813aaf0f66d4e4568f50c9f133277a4122411\n",
      "  Running setup.py bdist_wheel for Twisted ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/jonathan/Library/Caches/pip/wheels/91/c7/95/0bb4d45bc4ed91375013e9b5f211ac3ebf4138d8858f84abbc\n",
      "  Running setup.py bdist_wheel for zope.interface ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/jonathan/Library/Caches/pip/wheels/8b/39/98/0fcb72adfb12b2547273b1164d952f093f267e0324d58b6955\n",
      "Successfully built PyDispatcher Twisted zope.interface\n",
      "Installing collected packages: PyDispatcher, zope.interface, constantly, incremental, attrs, Automat, hyperlink, Twisted, cssselect, pyasn1, pyasn1-modules, service-identity, w3lib, parsel, queuelib, scrapy\n",
      "Successfully installed Automat-0.6.0 PyDispatcher-2.0.5 Twisted-17.9.0 attrs-17.4.0 constantly-15.1.0 cssselect-1.0.3 hyperlink-17.3.1 incremental-17.5.0 parsel-1.4.0 pyasn1-0.4.2 pyasn1-modules-0.2.1 queuelib-1.4.2 scrapy-1.5.0 service-identity-17.0.0 w3lib-1.19.0 zope.interface-4.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: *after installing Scrapy, quit Jupyter and restart this notebook\n",
    "\n",
    "\n",
    "### 1. Follow the scrapy tutorial here:\n",
    "\n",
    "https://doc.scrapy.org/en/latest/intro/tutorial.html\n",
    "\n",
    "#### the mock scrape we\n",
    "\n",
    "http://toscrape.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "            'http://quotes.toscrape.com/page/1/',\n",
    "            'http://quotes.toscrape.com/page/2/',\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = 'quotes-%s.html' % page\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.body)\n",
    "        self.log('Saved file %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-3.9.0-py2.py3-none-any.whl (942kB)\n",
      "\u001b[K    100% |████████████████████████████████| 952kB 1.2MB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: selenium\n",
      "Successfully installed selenium-3.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use Selenium to scrape javascript rendered page\n",
    "\n",
    "http://stanford.edu/~mgorkove/cgi-bin/rpython_tutorials/Scraping_a_Webpage_Rendered_by_Javascript_Using_Python.php\n",
    "\n",
    "Download chromedriver from: \n",
    "https://sites.google.com/a/chromium.org/chromedriver/downloads\n",
    "\n",
    "Move the chromedriver to a path , e.g. \"chromedriverpath\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chromedriverpath = '/Users/jonathan/Code/trial.ai/chromedriver'\n",
    "\n",
    "css_cat_path = 'https://www.chowsangsang.com/tc/product/Jewellery-ByCategory-Charms?page=0'\n",
    "css_product_path = 'https://www.chowsangsang.com/eshop-hk/zh_HK/%E8%B2%A8%E5%93%81/%E5%93%81%E7%89%8C%E7%B3%BB%E5%88%97/%E6%97%97%E8%89%A6%E7%B3%BB%E5%88%97/CHARME%E7%B3%BB%E5%88%97/Charme/p/PRD-90019GFC-489828?gaSrc=%E4%B8%B2%E9%A3%BE'\n",
    "\n",
    "cartier_cat_path = 'http://www.cartier.com/en-us/collections/jewelry/collections/juste-un-clou.viewall.html'\n",
    "cartier_product_path = 'http://www.cartier.com/en-us/collections/jewelry/exceptional-creations/high-jewelry-fauna-&-flora.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "browser = webdriver.Chrome(chromedriverpath) #replace with .Firefox(), or with the browser of your choice\n",
    "url = css_cat_path\n",
    "browser.get(url) #navigate to the page\n",
    "\n",
    "innerHTML = browser.execute_script(\"return document.body.innerHTML\") #returns the inner HTML as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44640"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "innerHTML.find('Charme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Charme'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "innerHTML[44640:44646]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parse using LXML \n",
    "\n",
    "http://stanford.edu/~mgorkove/cgi-bin/rpython_tutorials/webscraping_with_lxml.php\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524884"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(innerHTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
